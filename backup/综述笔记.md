对抗性训练：
核心是让模型在 “干净 + 对抗样本” 上学习，以适应带扰动的输入。从研究进展看：
方法演进：从 “基础混合训练” 发展到 “层级优化、成本优化、样本精细化筛选” 等复杂策略，兼顾 “鲁棒性” 与 “计算效率”“准确率平衡”。
场景覆盖：适配 “有标注 / 无标注数据”“物理可实现攻击 / 黑盒攻击” 等多类场景，满足不同应用需求。
未来趋势：更聚焦 “高效、精准、泛化性强” 的训练策略，平衡 “鲁棒性提升” 与 “训练成本、纯净样本准确率” 的权衡，同时结合细粒度样本分析（如难样本、友好样本）优化防御效果。

修改训练流程：
防御性蒸馏（DD）采用知识蒸馏技术训练具有鲁棒性的网络，其核心思路是用已训练网络的标签替换原始标签
强化自训练（RST）采用标准监督学习方法获取伪标签，并将其输入另一个以对抗鲁棒性为目标的网络，通过未标注数据弥合标准准确率与鲁棒准确率之间的差距。
防御训练的核心逻辑是通过 “调整训练流程、引入正则化 / 数据增强、优化神经元行为、利用特殊网络结构（如神经 ODE）” 等手段，提升模型对对抗攻击的鲁棒性。这类方法需反复迭代训练，虽能有效增强鲁棒性，但在已有运行模型中实施需额外工程成本。


使用补充网络：
在 “输入→分类” 流程中插入检测器，提前识别并拦截对抗样本
核心是主动净化输入，移除对抗性噪声：高级表征引导去噪器（HGD）生成式对抗网络（GAN）辅助
变种网络防御核心是改造网络结构，使其天生鲁棒
补充网络的核心逻辑是在 “输入到分类器” 流程中插入 “干预环节”：或提前检测拦截对抗样本，或主动净化噪声，或改造网络结构天生抗扰。优势是可 “外挂式” 部署（无需修改分类器），但需平衡检测准确性与计算开销。

变更网络架构：
变种网络的核心逻辑是从 “网络结构、基础组件、前端变换” 层面改造模型，实现 “天生抗扰”。优势是能从根源提升鲁棒性，但部分方法需修改原始架构，导致生产环境落地困难，且部分技术仍存在防御漏洞，需进一步优化。

执行网络验证：
网络验证的价值在于从 “实验（压缩、训练技巧）” 和 “理论（形式化验证、测试框架）” 两个维度，全面评估并保障模型鲁棒性，是 “鲁棒模型从训练到实际落地” 的关键衔接环节，但该领域仍面临 “实现细节复杂、部分技术落地难度大” 等挑战，有待进一步突破。



TP（真阳性）：模型正确预测为正类的样本数量；
TN（真阴性）：模型正确预测为负类的样本数量；
FP（假阳性）：模型错误地将负类预测为正类的样本数量；
FN（假阴性）：模型错误地将正类预测为负类的样本数量。

欺骗率FR是对抗攻击成功翻转标签的比例，反映了 “对抗攻击能让模型对图像标签判断出错的成功率”，从而衡量对抗攻击的有效性。